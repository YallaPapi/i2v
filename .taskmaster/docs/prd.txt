# PRD: Pinokio + Wan 2.2 on Vast.ai (CUDA 12.8)

## Overview
Set up a Vast.ai instance with Pinokio and Wan 2.2 for video generation. Wan 2.2 is already available in Pinokio via the WAN/Wan2GP app - just select it from "Selectable Generative Models".

## Goals
1. Create Vast.ai instance with CUDA 12.8 (nvidia/cuda:12.8.0-runtime-ubuntu22.04)
2. Install Pinokio
3. Install the WAN app (pinokiofactory/wan) inside Pinokio
4. Select Wan 2.2 model in the WAN app
5. Configure Cloudflare tunnel for remote access
6. Set up R2 auto-upload for generated videos

## Key Insight
**Wan 2.2 models are NOT downloaded separately.** They come with the WAN/Wan2GP Pinokio app. You install the app, then in its "Selectable Generative Models" config, you pick Wan 2.2 and it downloads automatically.

---

## Technical Requirements

### Instance Specifications
- GPU: RTX 5090 (32GB VRAM)
- Docker Image: nvidia/cuda:12.8.0-runtime-ubuntu22.04
- Disk: 100GB minimum
- RAM: 32GB+

### Software Stack
- CUDA 12.8
- Python 3.10+
- PyTorch 2.9.x cu128 (single install, no conflicts)
- Node.js (for Pinokio)
- Cloudflared (tunnel)

### Ports
- 22: SSH
- 3000: Pinokio web UI
- 8188: ComfyUI (if needed)

---

## Implementation Steps

### Phase 1: Instance Creation
1. Search Vast.ai for RTX 5090 with nvidia/cuda:12.8.0-runtime-ubuntu22.04
2. Request GPU with exposed ports: 3000, 8188
3. Create instance with onstart script

### Phase 2: Base Setup
```bash
apt-get update && apt-get install -y \
    git curl wget ca-certificates python3 python3-pip python3-venv nodejs npm

# libcuda symlink
ln -sf /usr/lib/x86_64-linux-gnu/libcuda.so.1 /usr/lib/x86_64-linux-gnu/libcuda.so

# Single PyTorch install (cu128 only - no conflicts)
pip install --index-url https://download.pytorch.org/whl/cu128 \
    "torch==2.9.0" "torchvision" "torchaudio"

# Cloudflared
curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o /usr/local/bin/cloudflared
chmod +x /usr/local/bin/cloudflared
```

### Phase 3: Pinokio Installation
```bash
# Install Pinokio
git clone https://github.com/pinokiocomputer/pinokio.git /opt/pinokio
cd /opt/pinokio
npm install
npm run build

# Start Pinokio server
node /opt/pinokio/dist/server.js --port 3000
```

### Phase 4: Install WAN App in Pinokio
1. Open Pinokio UI in browser
2. Search for "wan" or "Wan2GP" in Pinokio app store
3. Install the WAN app (https://github.com/pinokiofactory/wan)
4. Open WAN app configuration
5. In "Selectable Generative Models", enable Wan 2.2 entry (e.g., "Wan2.2-Animate-14B")
6. Trigger initial download - models cache automatically

### Phase 5: Cloudflare Tunnel
```bash
# Quick tunnel
cloudflared tunnel --url http://localhost:3000

# Or persistent tunnel with token
cloudflared tunnel run --token "YOUR_TOKEN"
```

### Phase 6: R2 Auto-Upload
Copy existing R2 upload scripts from SwarmUI setup:
- upload_to_r2.py
- auto_upload_watcher.py
- Configure to watch Pinokio's output directory

---

## Onstart Script

```bash
#!/bin/bash
exec > /var/log/onstart.log 2>&1
set -x

echo "=== PINOKIO SETUP STARTED ==="
date

# Base dependencies
apt-get update -qq
apt-get install -y -qq git curl wget python3 python3-pip python3-venv

# Node.js 20
curl -fsSL https://deb.nodesource.com/setup_20.x | bash -
apt-get install -y nodejs

# libcuda symlink
ln -sf /usr/lib/x86_64-linux-gnu/libcuda.so.1 /usr/lib/x86_64-linux-gnu/libcuda.so

# Single PyTorch cu128 install
pip install --index-url https://download.pytorch.org/whl/cu128 \
    "torch==2.9.0" "torchvision" "torchaudio"

# Cloudflared
curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o /usr/local/bin/cloudflared
chmod +x /usr/local/bin/cloudflared

# Install Pinokio
cd /root
git clone https://github.com/pinokiocomputer/pinokio.git
cd pinokio
npm install
npm run build

# Create data directories
mkdir -p /root/pinokio-data
mkdir -p /root/models

# Start Pinokio
nohup node dist/server.js --port 3000 > /var/log/pinokio.log 2>&1 &
sleep 10

# Start Cloudflare tunnel
nohup cloudflared tunnel --url http://localhost:3000 > /tmp/cloudflared.log 2>&1 &
sleep 5

echo "=== TUNNEL URL ==="
cat /tmp/cloudflared.log | grep -oE 'https://[a-z0-9-]+\.trycloudflare\.com' | head -1

echo "=== SETUP COMPLETE ==="
date
```

---

## After Instance Boots

1. SSH into instance, check /var/log/onstart.log
2. Get tunnel URL from /tmp/cloudflared.log
3. Open tunnel URL in browser
4. In Pinokio UI:
   - Search and install "wan" app
   - Open WAN app settings
   - Enable Wan 2.2 in "Selectable Generative Models"
   - Let models download
5. Test I2V generation:
   - Select Wan 2.2 model
   - Mode: Image-to-Video
   - Steps: 4 (Lightning)
   - FPS: 16, Duration: 5s
6. Verify GPU usage with nvidia-smi

---

## R2 Configuration
```
R2_ACCESS_KEY_ID=71555d910a08b613d28bdf23e8b32e57
R2_SECRET_ACCESS_KEY=7cd04dc1ba6e8904cab301612d208f8bca20ce76de9bf16fe846d94cdd3a563c
R2_ENDPOINT=https://6e8aca9b8012b19bf02fe00b5bb0d165.r2.cloudflarestorage.com
R2_BUCKET=i2v
R2_PUBLIC_DOMAIN=pub-10a867f870e7439f8178cad5f323ef29.r2.dev
```

## Cloudflare Tunnel Token
```
eyJhIjoiNmU4YWNhOWI4MDEyYjE5YmYwMmZlMDBiNWJiMGQxNjUiLCJ0IjoiZmU2ZjI1YTktZjU5Yi00NmYzLTk1NzgtN2MxOWNkN2ZhZjNlIiwicyI6Ik16WXdPR1kxTjJJdE1HUmxPUzAwT1dOaExUaGlZVE10WXpBM09XVmxOamxoTnpKbCJ9
```

---

## Success Criteria
1. Pinokio accessible via Cloudflare tunnel
2. WAN app installed with Wan 2.2 model selected
3. 5-second I2V clip generates in â‰¤5 minutes on RTX 5090
4. GPU shows utilization during generation
5. Videos auto-upload to R2

## Verification Commands
```bash
# Check GPU
nvidia-smi

# Check PyTorch CUDA
python3 -c "import torch; print(torch.version.cuda, torch.cuda.is_available())"

# Check Pinokio running
ps aux | grep pinokio

# Check tunnel
cat /tmp/cloudflared.log | grep trycloudflare
```
